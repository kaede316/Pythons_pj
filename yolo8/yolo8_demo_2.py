# -*- coding: utf-8 -*-
import cv2
from ultralytics import YOLO
import os
import sys


class YOLOv8Demo:
    def __init__(self, model_path='yolov8n.pt'):
        """
        åˆå§‹åŒ–YOLOv8æ¨¡å‹
        """
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨ä¼šè‡ªåŠ¨ä¸‹è½½
        if not os.path.exists(model_path) and model_path in ['yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt', 'yolov8l.pt',
                                                             'yolov8x.pt']:
            print(f"æ¨¡å‹æ–‡ä»¶ '{model_path}' ä¸å­˜åœ¨ï¼Œå°†è‡ªåŠ¨ä¸‹è½½...")

        # åŠ è½½æ¨¡å‹
        self.model = YOLO(model_path)
        print(f"æ¨¡å‹ '{model_path}' åŠ è½½æˆåŠŸï¼")

    def detect_image(self, image_path, output_path='detected_image.jpg', conf_threshold=0.5):
        """
        å¯¹å•å¼ å›¾åƒè¿›è¡Œç›®æ ‡æ£€æµ‹
        """
        if not os.path.exists(image_path):
            print(f"é”™è¯¯ï¼šå›¾åƒæ–‡ä»¶ '{image_path}' ä¸å­˜åœ¨ï¼")
            return False

        try:
            # æ‰§è¡Œé¢„æµ‹
            results = self.model.predict(source=image_path, conf=conf_threshold, save=False)
            # è·å–å¸¦æ ‡æ³¨çš„ç»“æœå›¾åƒ
            annotated_frame = results[0].plot()
            # ä¿å­˜ç»“æœå›¾åƒ
            cv2.imwrite(output_path, annotated_frame)
            print(f"âœ… å›¾åƒæ£€æµ‹å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³: {output_path}")

            # æ˜¾ç¤ºç»“æœå›¾åƒ
            cv2.imshow('YOLOv8 Image Detection', annotated_frame)
            print("æŒ‰ä»»æ„é”®å…³é—­å›¾åƒçª—å£...")
            cv2.waitKey(0)
            cv2.destroyAllWindows()
            return True

        except Exception as e:
            print(f"âŒ å›¾åƒæ£€æµ‹å¤±è´¥: {e}")
            return False

    def detect_video(self, video_path, output_path='detected_video.avi', conf_threshold=0.5):
        """
        å¯¹è§†é¢‘æ–‡ä»¶è¿›è¡Œç›®æ ‡æ£€æµ‹
        """
        if not os.path.exists(video_path):
            print(f"âŒ é”™è¯¯ï¼šè§†é¢‘æ–‡ä»¶ '{video_path}' ä¸å­˜åœ¨ï¼")
            return False

        try:
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                print("âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶ã€‚")
                return False

            # è·å–è§†é¢‘ä¿¡æ¯
            fps = int(cap.get(cv2.CAP_PROP_FPS))
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fourcc = cv2.VideoWriter_fourcc(*'XVID')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

            print("ğŸ¥ å¼€å§‹è§†é¢‘æ£€æµ‹ï¼ŒæŒ‰ 'q' é”®å¯ä¸­æ–­...")
            frame_count = 0

            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break

                # å¯¹å½“å‰å¸§è¿›è¡Œæ¨ç†
                results = self.model.predict(frame, conf=conf_threshold, verbose=False)
                annotated_frame = results[0].plot()

                # å†™å…¥è¾“å‡ºè§†é¢‘
                out.write(annotated_frame)

                # å®æ—¶æ˜¾ç¤ºå½“å‰å¸§
                cv2.imshow('YOLOv8 Video Detection', annotated_frame)
                frame_count += 1

                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

            cap.release()
            out.release()
            cv2.destroyAllWindows()
            print(f"âœ… è§†é¢‘æ£€æµ‹å®Œæˆï¼å¤„ç†äº† {frame_count} å¸§ï¼Œç»“æœå·²ä¿å­˜è‡³: {output_path}")
            return True

        except Exception as e:
            print(f"âŒ è§†é¢‘æ£€æµ‹å¤±è´¥: {e}")
            return False

    def detect_camera(self, camera_id=0, conf_threshold=0.5):
        """
        ä½¿ç”¨æ‘„åƒå¤´è¿›è¡Œå®æ—¶ç›®æ ‡æ£€æµ‹
        """
        # å…ˆæµ‹è¯•æ‘„åƒå¤´æ˜¯å¦å¯ç”¨
        if not self.test_camera(camera_id):
            print(f"âŒ æ‘„åƒå¤´ {camera_id} ä¸å¯ç”¨ï¼Œå°è¯•è‡ªåŠ¨æ£€æµ‹å¯ç”¨æ‘„åƒå¤´...")
            available_cam = self.find_available_camera()
            if available_cam is not None:
                print(f"ğŸ” å‘ç°å¯ç”¨æ‘„åƒå¤´: ID {available_cam}")
                camera_id = available_cam
            else:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„æ‘„åƒå¤´ï¼")
                return False

        try:
            cap = cv2.VideoCapture(camera_id)
            if not cap.isOpened():
                print(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {camera_id}")
                return False

            print(f"ğŸ“· å¼€å§‹æ‘„åƒå¤´ {camera_id} å®æ—¶æ£€æµ‹ï¼ŒæŒ‰ 'ESC' é”®é€€å‡º...")
            print("ğŸ’¡ æç¤ºï¼šç¡®ä¿æ‘„åƒå¤´æ²¡æœ‰è¢«å…¶ä»–ç¨‹åºå ç”¨")

            frame_count = 0
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    print("âŒ æ— æ³•è·å–è§†é¢‘å¸§")
                    break

                # æ¨ç†å½“å‰å¸§
                results = self.model.predict(frame, conf=conf_threshold, verbose=False)
                annotated_frame = results[0].plot()

                # æ˜¾ç¤ºå¸§ç‡ä¿¡æ¯
                fps_text = f"FPS: {int(cap.get(cv2.CAP_PROP_FPS))} | Frame: {frame_count}"
                cv2.putText(annotated_frame, fps_text, (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

                cv2.imshow(f'YOLOv8 Camera {camera_id}', annotated_frame)
                frame_count += 1

                # æŒ‰ESCé”®é€€å‡º
                if cv2.waitKey(1) == 27:
                    break

            cap.release()
            cv2.destroyAllWindows()
            print(f"âœ… æ‘„åƒå¤´æ£€æµ‹ç»“æŸï¼Œå…±å¤„ç† {frame_count} å¸§")
            return True

        except Exception as e:
            print(f"âŒ æ‘„åƒå¤´æ£€æµ‹å¤±è´¥: {e}")
            return False

    def test_camera(self, camera_id):
        """æµ‹è¯•æ‘„åƒå¤´æ˜¯å¦å¯ç”¨"""
        cap = cv2.VideoCapture(camera_id)
        if cap.isOpened():
            ret, frame = cap.read()
            cap.release()
            return ret
        return False

    def find_available_camera(self):
        """è‡ªåŠ¨æ£€æµ‹å¯ç”¨çš„æ‘„åƒå¤´"""
        print("ğŸ” æ­£åœ¨æ‰«æå¯ç”¨æ‘„åƒå¤´...")
        for i in range(0, 5):  # æ£€æŸ¥å‰5ä¸ªæ‘„åƒå¤´è®¾å¤‡
            if self.test_camera(i):
                print(f"  æ‘„åƒå¤´ {i}: âœ… å¯ç”¨")
                return i
            else:
                print(f"  æ‘„åƒå¤´ {i}: âŒ ä¸å¯ç”¨")
        return None

    def list_available_cameras(self):
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ‘„åƒå¤´"""
        print("ğŸ“‹ å¯ç”¨æ‘„åƒå¤´åˆ—è¡¨:")
        available_cams = []
        for i in range(0, 5):
            if self.test_camera(i):
                print(f"  ğŸ“· æ‘„åƒå¤´ ID {i}: âœ… å¯ç”¨")
                available_cams.append(i)
            else:
                print(f"  ğŸ“· æ‘„åƒå¤´ ID {i}: âŒ ä¸å¯ç”¨")
        return available_cams


def create_test_image():
    """åˆ›å»ºæµ‹è¯•å›¾åƒ"""
    import numpy as np
    test_img = np.ones((400, 600, 3), dtype=np.uint8) * 255  # ç™½è‰²èƒŒæ™¯

    # æ·»åŠ ä¸€äº›æµ‹è¯•å›¾å½¢
    cv2.rectangle(test_img, (100, 100), (200, 200), (255, 0, 0), -1)  # è“è‰²çŸ©å½¢
    cv2.circle(test_img, (400, 200), 50, (0, 255, 0), -1)  # ç»¿è‰²åœ†å½¢
    cv2.putText(test_img, 'YOLOv8 Test Image', (150, 350),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

    cv2.imwrite('test_image.jpg', test_img)
    return 'test_image.jpg'


if __name__ == '__main__':
    # åˆå§‹åŒ–Demo
    demo = YOLOv8Demo(model_path='yolov8n.pt')

    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_image_path = create_test_image()
    print(f"ğŸ“¸ å·²åˆ›å»ºæµ‹è¯•å›¾åƒ: {test_image_path}")

    while True:
        print("\n" + "=" * 60)
        print("ğŸ¯ YOLOv8 Demo åŠŸèƒ½èœå•")
        print("=" * 60)
        print("1. ğŸ“· å›¾åƒæ£€æµ‹ (ä½¿ç”¨æµ‹è¯•å›¾åƒ)")
        print("2. ğŸ¥ è§†é¢‘æ£€æµ‹ (éœ€è¦æä¾›è§†é¢‘æ–‡ä»¶è·¯å¾„)")
        print("3. ğŸ“¹ æ‘„åƒå¤´å®æ—¶æ£€æµ‹")
        print("4. ğŸ” æŸ¥çœ‹å¯ç”¨æ‘„åƒå¤´")
        print("5. âŒ é€€å‡ºç¨‹åº")
        print("=" * 60)

        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-5): ").strip()

        if choice == '1':
            # å›¾åƒæ£€æµ‹
            demo.detect_image(image_path=test_image_path,
                              output_path='result_image.jpg',
                              conf_threshold=0.5)

        elif choice == '2':
            # è§†é¢‘æ£€æµ‹
            video_path = input("è¯·è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„ (æˆ–è¾“å…¥ 'test' ä½¿ç”¨ç¤ºä¾‹è§†é¢‘): ").strip()
            if video_path.lower() == 'test':
                print("âŒ è¯·æä¾›æ‚¨è‡ªå·±çš„è§†é¢‘æ–‡ä»¶è·¯å¾„")
                print("ğŸ’¡ æç¤ºï¼šæ‚¨å¯ä»¥ä»ç½‘ä¸Šä¸‹è½½ä¸€ä¸ªæµ‹è¯•è§†é¢‘ï¼Œæˆ–ä½¿ç”¨æ‰‹æœºæ‹æ‘„")
            else:
                demo.detect_video(video_path=video_path,
                                  output_path='result_video.avi',
                                  conf_threshold=0.5)

        elif choice == '3':
            # æ‘„åƒå¤´æ£€æµ‹
            demo.list_available_cameras()
            camera_input = input("è¯·è¾“å…¥æ‘„åƒå¤´ID (ç›´æ¥å›è½¦ä½¿ç”¨è‡ªåŠ¨æ£€æµ‹): ").strip()

            if camera_input:
                try:
                    camera_id = int(camera_input)
                    demo.detect_camera(camera_id=camera_id, conf_threshold=0.5)
                except ValueError:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            else:
                demo.detect_camera(conf_threshold=0.5)

        elif choice == '4':
            # æŸ¥çœ‹å¯ç”¨æ‘„åƒå¤´
            demo.list_available_cameras()

        elif choice == '5':
            print("ğŸ‘‹ ç¨‹åºé€€å‡ºï¼Œæ„Ÿè°¢ä½¿ç”¨ï¼")
            break

        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

        # æš‚åœä¸€ä¸‹è®©ç”¨æˆ·çœ‹åˆ°ç»“æœ
        input("\næŒ‰å›è½¦é”®ç»§ç»­...")

    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if os.path.exists('test_image.jpg'):
        os.remove('test_image.jpg')
        print("ğŸ§¹ å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶")