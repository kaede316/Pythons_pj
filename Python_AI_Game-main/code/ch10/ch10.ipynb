{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('FrozenLake-v1',render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(16)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.0, False, False, {'prob': 0.3333333333333333})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "env.render()\n",
    "env.step(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_policy(pi, env, n_cols=4):\n",
    "    print('Policy:')\n",
    "    arrs = {k:v for k,v in enumerate(('<', 'v', '>', '^'))}\n",
    "    nS = env.observation_space.n\n",
    "    for s in range(nS):\n",
    "        a = pi(s)\n",
    "        print(\"| \", end=\"\")\n",
    "        if s in [5,7,11,12,15]:\n",
    "            print(\"\".rjust(9), end=\" \")\n",
    "        else:\n",
    "            print(str(s).zfill(2), arrs[a].rjust(6), end=\" \")\n",
    "        if (s + 1) % n_cols == 0: print(\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_game(env, pi):\n",
    "    results = []\n",
    "    for _ in range(100):\n",
    "        state,_ = env.reset()\n",
    "        Done = False\n",
    "        while not Done:\n",
    "            action = pi(state)\n",
    "            state, reward, Done, _ ,_= env.step(action)\n",
    "        results.append(reward>0)\n",
    "    return np.sum(results)/len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy:\n",
      "| 00      < | 01      < | 02      ^ | 03      ^ |\n",
      "| 04      > |           | 06      v |           |\n",
      "| 08      v | 09      > | 10      v |           |\n",
      "|           | 13      < | 14      v |           |\n",
      "Reaches goal 4.00%. \n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v1')\n",
    "env.reset()\n",
    "random_pi = lambda s: {k:v for k in range(16) for v in np.random.choice(4,16)}[s]\n",
    "\n",
    "print_policy(random_pi,env)\n",
    "print('Reaches goal {:.2f}%. '.format(\n",
    "    test_game(env, random_pi)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy:\n",
      "| 00      > | 01      > | 02      v | 03      < |\n",
      "| 04      v |           | 06      v |           |\n",
      "| 08      > | 09      > | 10      v |           |\n",
      "|           | 13      > | 14      > |           |\n",
      "Reaches goal 2.00%. \n"
     ]
    }
   ],
   "source": [
    "LEFT, DOWN, RIGHT, UP = range(4)\n",
    "human_pi = lambda s: {\n",
    "    0:RIGHT, 1:RIGHT, 2:DOWN, 3:LEFT,\n",
    "    4:DOWN, 5:LEFT, 6:DOWN, 7:LEFT,\n",
    "    8:RIGHT, 9:RIGHT, 10:DOWN, 11:LEFT,\n",
    "    12:LEFT, 13:RIGHT, 14:RIGHT, 15:LEFT\n",
    "}[s]\n",
    "print_policy(human_pi, env)\n",
    "print('Reaches goal {:.2f}%. '.format(\n",
    "    test_game(env, human_pi)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mento carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state, Q, mode=\"both\"):\n",
    "    if mode == \"explore\":\n",
    "        return np.random.randint(len(Q[state]))\n",
    "    if mode == \"exploit\":\n",
    "        return np.argmax(Q[state])\n",
    "    if mode == \"both\":\n",
    "        if np.random.random() > 0.5:\n",
    "            return np.argmax(Q[state])\n",
    "        else:\n",
    "            return np.random.randint(len(Q[state]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(env, Q ,max_steps=200):\n",
    "    state, _ = env.reset()\n",
    "    episode = []\n",
    "    finished = False\n",
    "    step = 0\n",
    "\n",
    "    while not finished:\n",
    "        action = select_action(state, Q, mode='both')\n",
    "        next_state, reward, finished, _, _ = env.step(action)\n",
    "        experience = (state, action, finished,reward)\n",
    "        episode.append(experience)\n",
    "        if step >= max_steps:\n",
    "            break\n",
    "        state = next_state\n",
    "        step += 1\n",
    "\n",
    "    return np.array(episode,dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo(env, episodes=10000, test_policy_freq=1000):\n",
    "    nS, nA = env.observation_space.n, env.action_space.n\n",
    "    Q = np.zeros((nS, nA), dtype=np.float64)\n",
    "    returns = {} \n",
    "\n",
    "    for i in range(episodes): \n",
    "        episode = play_game(env, Q)\n",
    "        visited = np.zeros((nS, nA), dtype=bool)\n",
    "\n",
    "        for t, (state, action, _, _) in enumerate(episode):\n",
    "            state_action = (state, action)\n",
    "            if not visited[state][action]:\n",
    "                visited[state][action] = True\n",
    "                discount = np.array([0.9**i for i in range(len(episode[t:]))])\n",
    "                reward = episode[t:, -1]\n",
    "                G = np.sum( discount * reward)\n",
    "                if returns.get(state_action):\n",
    "                    returns[state_action].append(G)\n",
    "                else:\n",
    "                    returns[state_action] = [G]  \n",
    "\n",
    "                Q[state][action] = sum(returns[state_action]) / len(returns[state_action])\n",
    "\n",
    "        pi = lambda s: {s:a for s, a in enumerate(np.argmax(Q, axis=1))}[s]\n",
    "\n",
    "        if i % test_policy_freq == 0:\n",
    "                print(\"Test episode {} Reaches goal {:.2f}%. \".format\n",
    "                (i, test_game(env, pi)*100))\n",
    "            \n",
    "    return pi,Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test episode 0 Reaches goal 0.00%. \n",
      "Test episode 1000 Reaches goal 22.00%. \n",
      "Test episode 2000 Reaches goal 27.00%. \n",
      "Test episode 3000 Reaches goal 14.00%. \n",
      "Test episode 4000 Reaches goal 22.00%. \n",
      "Test episode 5000 Reaches goal 30.00%. \n",
      "Test episode 6000 Reaches goal 16.00%. \n",
      "Test episode 7000 Reaches goal 29.00%. \n",
      "Test episode 8000 Reaches goal 22.00%. \n",
      "Test episode 9000 Reaches goal 24.00%. \n",
      "Test episode 10000 Reaches goal 35.00%. \n",
      "Test episode 11000 Reaches goal 37.00%. \n",
      "Test episode 12000 Reaches goal 28.00%. \n",
      "Test episode 13000 Reaches goal 45.00%. \n",
      "Test episode 14000 Reaches goal 44.00%. \n",
      "Test episode 15000 Reaches goal 40.00%. \n",
      "Test episode 16000 Reaches goal 46.00%. \n",
      "Test episode 17000 Reaches goal 47.00%. \n",
      "Test episode 18000 Reaches goal 47.00%. \n",
      "Test episode 19000 Reaches goal 45.00%. \n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v1')\n",
    "policy_mc,Q = monte_carlo(env,episodes=20000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy:\n",
      "| 00      v | 01      ^ | 02      > | 03      ^ |\n",
      "| 04      < |           | 06      < |           |\n",
      "| 08      ^ | 09      v | 10      < |           |\n",
      "|           | 13      > | 14      v |           |\n",
      "Reaches goal 44.00%. \n"
     ]
    }
   ],
   "source": [
    "print_policy(policy_mc,env)\n",
    "print('Reaches goal {:.2f}%. '.format(\n",
    "    test_game(env, policy_mc)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state, Q):\n",
    "    Qvalue = Q[state]\n",
    "    norm_Q = Qvalue - np.max(Qvalue)\n",
    "    exp_Q = np.exp(norm_Q)\n",
    "    probs = exp_Q / np.sum(exp_Q)\n",
    "    return np.random.choice(len(Qvalue), p=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarsa(env,lr = 0.01,episodes=100, gamma=0.9,test_policy_freq=1000):\n",
    "    nS, nA = env.observation_space.n, env.action_space.n\n",
    "    Q = np.zeros((nS, nA), dtype=np.float64)\n",
    "    \n",
    "    for i in range(episodes): \n",
    "        state, _ = env.reset()\n",
    "        finished = False\n",
    "        action = select_action(state, Q)\n",
    "        while not finished:\n",
    "            next_state, reward, finished, _, _ = env.step(action)\n",
    "            next_action = select_action(next_state, Q)\n",
    "            target = reward + gamma * Q[next_state][next_action] * (not finished)\n",
    "            error = target - Q[state][action]\n",
    "            Q[state][action] = Q[state][action] + lr * error\n",
    "            state, action = next_state, next_action\n",
    "\n",
    "        pi = lambda s: {s:a for s, a in enumerate(np.argmax(Q, axis=1))}[s]\n",
    "        \n",
    "        if i % test_policy_freq == 0:\n",
    "                print(\"Test episode {} Reaches goal {:.2f}%. \".format\n",
    "                (i, test_game(env, pi,)*100))\n",
    "\n",
    "    return pi,Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test episode 0 Reaches goal 0.00%. \n",
      "Test episode 1000 Reaches goal 9.00%. \n",
      "Test episode 2000 Reaches goal 7.00%. \n",
      "Test episode 3000 Reaches goal 5.00%. \n",
      "Test episode 4000 Reaches goal 10.00%. \n",
      "Test episode 5000 Reaches goal 9.00%. \n",
      "Test episode 6000 Reaches goal 19.00%. \n",
      "Test episode 7000 Reaches goal 18.00%. \n",
      "Test episode 8000 Reaches goal 18.00%. \n",
      "Test episode 9000 Reaches goal 26.00%. \n",
      "Test episode 10000 Reaches goal 15.00%. \n",
      "Test episode 11000 Reaches goal 22.00%. \n",
      "Test episode 12000 Reaches goal 45.00%. \n",
      "Test episode 13000 Reaches goal 36.00%. \n",
      "Test episode 14000 Reaches goal 7.00%. \n",
      "Test episode 15000 Reaches goal 48.00%. \n",
      "Test episode 16000 Reaches goal 45.00%. \n",
      "Test episode 17000 Reaches goal 11.00%. \n",
      "Test episode 18000 Reaches goal 16.00%. \n",
      "Test episode 19000 Reaches goal 7.00%. \n",
      "Test episode 20000 Reaches goal 14.00%. \n",
      "Test episode 21000 Reaches goal 29.00%. \n",
      "Test episode 22000 Reaches goal 19.00%. \n",
      "Test episode 23000 Reaches goal 5.00%. \n",
      "Test episode 24000 Reaches goal 70.00%. \n",
      "Test episode 25000 Reaches goal 25.00%. \n",
      "Test episode 26000 Reaches goal 54.00%. \n",
      "Test episode 27000 Reaches goal 73.00%. \n",
      "Test episode 28000 Reaches goal 18.00%. \n",
      "Test episode 29000 Reaches goal 65.00%. \n",
      "Test episode 30000 Reaches goal 42.00%. \n",
      "Test episode 31000 Reaches goal 20.00%. \n",
      "Test episode 32000 Reaches goal 39.00%. \n",
      "Test episode 33000 Reaches goal 25.00%. \n",
      "Test episode 34000 Reaches goal 26.00%. \n",
      "Test episode 35000 Reaches goal 21.00%. \n",
      "Test episode 36000 Reaches goal 20.00%. \n",
      "Test episode 37000 Reaches goal 69.00%. \n",
      "Test episode 38000 Reaches goal 77.00%. \n",
      "Test episode 39000 Reaches goal 74.00%. \n",
      "Test episode 40000 Reaches goal 54.00%. \n",
      "Test episode 41000 Reaches goal 79.00%. \n",
      "Test episode 42000 Reaches goal 65.00%. \n",
      "Test episode 43000 Reaches goal 24.00%. \n",
      "Test episode 44000 Reaches goal 30.00%. \n",
      "Test episode 45000 Reaches goal 23.00%. \n",
      "Test episode 46000 Reaches goal 37.00%. \n",
      "Test episode 47000 Reaches goal 10.00%. \n",
      "Test episode 48000 Reaches goal 18.00%. \n",
      "Test episode 49000 Reaches goal 29.00%. \n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v1')\n",
    "policy_sarsa,Q_sarsa = sarsa(env,lr=0.01,episodes=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy:\n",
      "| 00      < | 01      ^ | 02      < | 03      ^ |\n",
      "| 04      < |           | 06      > |           |\n",
      "| 08      ^ | 09      v | 10      < |           |\n",
      "|           | 13      > | 14      v |           |\n",
      "Reaches goal 78.00%. \n"
     ]
    }
   ],
   "source": [
    "print_policy(policy_sarsa,env)\n",
    "print('Reaches goal {:.2f}%. '.format(\n",
    "    test_game(env, policy_sarsa)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state, Q,temp):\n",
    "    Qvalue = Q[state]\n",
    "    scaled_Q = Qvalue / temp\n",
    "    norm_Q = scaled_Q - np.max(scaled_Q)\n",
    "    exp_Q = np.exp(norm_Q)\n",
    "    probs = exp_Q / np.sum(exp_Q)\n",
    "    return np.random.choice(len(Qvalue), p=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning(env,lr = 0.001,episodes=100, gamma=0.9,test_policy_freq=1000):\n",
    "    nS, nA = env.observation_space.n, env.action_space.n\n",
    "    Q = np.zeros((nS, nA), dtype=np.float64)\n",
    "    temp_array = np.logspace(0,-2,num=episodes)\n",
    "    for i in range(episodes): \n",
    "        state, _ = env.reset()\n",
    "        finished = False\n",
    "        while not finished:\n",
    "            action = select_action(state, Q,temp_array[i])\n",
    "            next_state, reward, finished, _, _ = env.step(action)\n",
    "            target = reward + gamma * Q[next_state].max() * (not finished)\n",
    "            error = target - Q[state][action]\n",
    "            Q[state][action] = Q[state][action] + lr * error\n",
    "            state = next_state\n",
    "\n",
    "        pi = lambda s: {s:a for s, a in enumerate(np.argmax(Q, axis=1))}[s]\n",
    "        \n",
    "        if i % test_policy_freq == 0:\n",
    "                print(\"Test episode {} Reaches goal {:.2f}%. \".format\n",
    "                (i, test_game(env, pi)*100))\n",
    "\n",
    "    return pi,Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test episode 0 Reaches goal 0.00%. \n",
      "Test episode 1000 Reaches goal 5.00%. \n",
      "Test episode 2000 Reaches goal 26.00%. \n",
      "Test episode 3000 Reaches goal 22.00%. \n",
      "Test episode 4000 Reaches goal 18.00%. \n",
      "Test episode 5000 Reaches goal 31.00%. \n",
      "Test episode 6000 Reaches goal 16.00%. \n",
      "Test episode 7000 Reaches goal 25.00%. \n",
      "Test episode 8000 Reaches goal 23.00%. \n",
      "Test episode 9000 Reaches goal 23.00%. \n",
      "Test episode 10000 Reaches goal 43.00%. \n",
      "Test episode 11000 Reaches goal 29.00%. \n",
      "Test episode 12000 Reaches goal 29.00%. \n",
      "Test episode 13000 Reaches goal 40.00%. \n",
      "Test episode 14000 Reaches goal 48.00%. \n",
      "Test episode 15000 Reaches goal 45.00%. \n",
      "Test episode 16000 Reaches goal 42.00%. \n",
      "Test episode 17000 Reaches goal 30.00%. \n",
      "Test episode 18000 Reaches goal 29.00%. \n",
      "Test episode 19000 Reaches goal 20.00%. \n",
      "Test episode 20000 Reaches goal 65.00%. \n",
      "Test episode 21000 Reaches goal 71.00%. \n",
      "Test episode 22000 Reaches goal 41.00%. \n",
      "Test episode 23000 Reaches goal 70.00%. \n",
      "Test episode 24000 Reaches goal 54.00%. \n",
      "Test episode 25000 Reaches goal 57.00%. \n",
      "Test episode 26000 Reaches goal 65.00%. \n",
      "Test episode 27000 Reaches goal 59.00%. \n",
      "Test episode 28000 Reaches goal 70.00%. \n",
      "Test episode 29000 Reaches goal 42.00%. \n",
      "Test episode 30000 Reaches goal 65.00%. \n",
      "Test episode 31000 Reaches goal 68.00%. \n",
      "Test episode 32000 Reaches goal 73.00%. \n",
      "Test episode 33000 Reaches goal 75.00%. \n",
      "Test episode 34000 Reaches goal 47.00%. \n",
      "Test episode 35000 Reaches goal 81.00%. \n",
      "Test episode 36000 Reaches goal 74.00%. \n",
      "Test episode 37000 Reaches goal 83.00%. \n",
      "Test episode 38000 Reaches goal 76.00%. \n",
      "Test episode 39000 Reaches goal 77.00%. \n",
      "Test episode 40000 Reaches goal 75.00%. \n",
      "Test episode 41000 Reaches goal 75.00%. \n",
      "Test episode 42000 Reaches goal 63.00%. \n",
      "Test episode 43000 Reaches goal 76.00%. \n",
      "Test episode 44000 Reaches goal 79.00%. \n",
      "Test episode 45000 Reaches goal 77.00%. \n",
      "Test episode 46000 Reaches goal 62.00%. \n",
      "Test episode 47000 Reaches goal 77.00%. \n",
      "Test episode 48000 Reaches goal 81.00%. \n",
      "Test episode 49000 Reaches goal 83.00%. \n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v1')\n",
    "policy_q_learning,Q_q_learning = q_learning(env,lr=0.01,episodes=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy:\n",
      "| 00      < | 01      ^ | 02      > | 03      ^ |\n",
      "| 04      < |           | 06      < |           |\n",
      "| 08      ^ | 09      v | 10      < |           |\n",
      "|           | 13      > | 14      v |           |\n",
      "Reaches goal 74.00%. \n"
     ]
    }
   ],
   "source": [
    "print_policy(policy_q_learning,env)\n",
    "print('Reaches goal {:.2f}%. '.format(\n",
    "    test_game(env, policy_q_learning)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('game')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "582c0b5fdb7e7ad1f1050fd1e5a23890c962b6c6199ffd519a966d6976476f17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
